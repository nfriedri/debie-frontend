<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DEBIE - Webapp</title>
 <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"> -->
  <link href="https://getbootstrap.com/docs/4.2/dist/css/bootstrap.min.css" rel="stylesheet">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script>
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
    <!--<link href="style.css" rel="stylesheet">-->
    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.8.0"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-md navbar-light bg-light sticky-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="index.html"><img src="img/logo.png" height="10%" width="30%"></a>           <!-- Logo in Navigation oben links -->
            <a class="navbar-brand-center" href="index.html"><img src="img/logo2.png" height="40%" width="40%"> </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="index.html">Home</a>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="about.html">About</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="bias-evaluation.html">BiasEvaluation</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="debiasing.html">Debiasing</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container-fluid">
        <div class="jumbotron bg-dark text-white px-md-5">
            <h1 class="display-4">DEBIE</h1>
            <p class="lead">This web application evalutes bias in word embeddings out of bias specifications and removes the bias as far as possible from them through debiasing. 
                </p>
            <hr class="my-4">
            <p>In the following a short introduction to the topics "word embeddings", "implicit and explixit bias", "bias evaluation" and "debiasing" is presented</p>
            <p class="lead">
            </p>
        </div>
    </div>
    <div class="container-fluid">
            <div class="jumbotron">
                <h1 class="display-4">Word Embeddings</h1>
                <hr class="my-4">
                <p class="lead">Usage</p> 
                <p>In the web application DEBIE 4 different embedding spaces are provided for retrieving word vector representations. Alternatively, additionall embedding spaces can be uploaded. 
                    Fastened to the application are 4 databases containing pre-trained word vector representations retrieved through training the fastText, CBOW, Skip-Gram and GloVe and models on wikipedia word corpora.
                    The contained vectors for fastText, CBOW and GloVe have the dimension 300 and the Skip-Gram vectors have the dimension 250. 
                    For further details on the used vector training models, please follow the links to the references provided below under "Pre-trained word embeddings".
                    By uploading your own embedding space, please pay attention that all vectors have the same dimensionality, otherwise a correct computation can not be ensured.
                    If you want to start multiple requests with your own embedding space please do not upload your embedding space multiple times, instead just copy the name of the database and insert it 
                    into the field on top, called "Selected File". The system will then retrieve your file from its memory automatically.
                </p>
          </div>
        </div>

    <div class="container-fluid">
        <div class="jumbotron">
            <h1 class="display-4">Bias Evaluation</h1>
            <hr class="my-4">
            <p class="lead">Usage</p> 
            <p>The Evaluation Engine offers the possibility to either evaluate bias on pre-defined test sets or to evaluate bias in self-defined test sets.</p>
            <p class="lead">Pre-defined test sets</p>
            <p>By retrieving bias evaluations from the pre-defined test sets, simply choose the wanted evaluation methods and the embedding space in the selection bar on top of 
                the site and click on the 'Evaluate'-button. There are 4 methods offered, the embedding coherence test (ECT), the bias analogy test (BAT) or
                the word embedding association test (WEAT) for evaluating explicit bias specifications and the k Means++ clustering algorithm for measuring implicit bias. 
                Alternatively it is offered to simply run all evaluation methods, but please be aware that this can take a certain amount of time, depending on the size of the test set.
                If certain words are not contained in the databases, the term sets of the specifications are adjustet to the same size by removing values randomly.
                This is done to ensure that the sets all have the same size.
                To accelerate the calculation of the WEAT test, only the first 1000 random permutations are taken into account for the p-value computation.
                <br>
                The presented pre-defined test sets are introduced by <a href="https://arxiv.org/abs/1608.07187">Caliskan et. al. (2017)</a> as WEAT T8 and WEAT T1 
                test sets in the paper "Semantics derived automatically from language corpora contain human-like biases".
            </p>
            <p class="lead">Self-defined test sets</p>
            <p>Alternatively it is offerd to evaluate self-defined test sets under "Upload your own test". Simply enter the words for the target term sets and the attribute term sets 
                seperated by whitespaces into the corresponding fields. Field T1 is for the first target term set, field T2 for the second target term set, field A1 for the first attribute term set and
                field A2 is for the second attribute term set. For evaluating, the same embedding spaces and evaluation methods are offered than for pre-defined test sets.
                These can be selected in the selection bar on top of the site.
                <br>
                Additionally, it is offered to upload the test set in a JSON file on the bottom of the side. Therefore, simply pack the input word list into one of the 
                provided formats which can be found under "Accepted Files & Formats". It is possible to upload the file containing only the word lists or if the switch-button is selected,
                the vectors have to be uploaded together with the terms.
            </p>
      </div>
    </div>

    <div class="container-fluid">
            <div class="jumbotron">
                <h1 class="display-4">Debiasing</h1>
                <hr class="my-4">
                <p class="lead">Usage</p> 
                <p>This webapplication gives the possibility to either evaluate the bias on the predefined test sets or to evaluate own defined test and attribute sets.</p>
                <p class="lead">Pre-defined test sets</p>
                <p>By debiasing pre-defined test sets, simply select the embedding space for vector retrieval and one of the 4 offered debiasing models in the selection bar on top of 
                    the site and press on the 'Debias'-button under the test set which should be debiased. For debiasing, the General Bias-Direction Debiasing (GBDD) and the Bias Analogy Model (BAM)
                    are offered together with their compositions GBDD x BAM and BAM x GBDD.
                    If the switch-button "Enable-PCA" is selected, the application retrieves additionally to the debiased vectors in full dimension their values with a dimension of 2, 
                    reduced by performing a principal components analysis (PCA). Next to the results, a diagram is displayed comparing the biased and debiased vectors.
                    <br>
                    The presented pre-defined test sets are introduced by <a href="https://arxiv.org/abs/1608.07187">Caliskan et. al. (2017)</a> as WEAT T8 and WEAT T1 
                    test sets in the paper "Semantics derived automatically from language corpora contain human-like biases".
                </p>
                <p class="lead">Self-defined test sets</p>
                <p>Alternatively it is offered to debias selff defined test sets.
                    Therefore, simply select the embedding space for vector retrieval and one of the 4 offered debiasing models in the selection bar on top of the site.
                    The debiasing models are trained by using augmentations of the provided input words. 
                    These can either be retrieved by the system or can be specified in the input by pressing the offered augments switch-button and entering the word lists in the offered fields.
                    The words in the words list have to be separated by blanc spaces.
                    If the "Enable-PCA" switch-button on top is selected, the application retrieves additionally to the debiased vectors in full dimension their values with a dimension of 2, 
                    reduced by performing a principal components analysis (PCA). Next to the results, a diagram is displayed comparing the biased and debiased vectors.
                </p>
          </div>
        </div>

    <div class="container-fluid">
        <div class="jumbotron">
            <h1 class="display-4">Accepted Files & Formats</h1>
            <hr class="my-4">
            <p class="lead">API accepted JSON-formats</p>
            <div class="row">
            <div class="col">
                <a>For Evaluation & Debiasing with augmentation flag = false:</a> 
                <p><pre><code>
{
    "T1": "string",
    "T2": "string",
    "A1": "string",
    "A2": "string"
}
                </code></pre></p>
                <a>For Debiasing with augmentation flag = true:</a>
                <p><pre><code></code>
{
    "T1": "string",
    "T2": "string",
    "A1": "string",
    "A2": "string",
    "AugT1": "string",
    "AugT2": "string",
    "AugA1": "string",
    "AugA2": "string"
}
                </code></pre></p>
        </div>
        <div class="col"> 
            <a>For Evaluation & Debiasing with vector flag = true and augmentation flag = false</a>
            <p><pre><code>
{
    "T1": [
        {
        "word": "string", 
        "vector": "string"
        }
    ],
    "T2": [
        {
        "word": "string",
        "vector": "string"
        }
    ],
    "A1": [
        {
        "word": "string", 
        "vector": "string" 
        } 
    ], 
    "A2": [ 
        { 
        "word": "string", 
        "vector": "string" 
        } 
    ]
}
            </code></pre></p>
        </div>
        <div class="col">
            <a>For Evaluation & Debiasing with vector flag = true and augmentation flag = true</a>
        <p><pre><code>
{
    "T1": [
        {
        "word": "string", 
        "vector": "string"
        }
    ],
    "T2": [
        {
        "word": "string",
        "vector": "string"
        }
    ],
    "A1": [
        {
        "word": "string", 
        "vector": "string" 
        } 
    ], 
    "A2": [ 
        { 
        "word": "string", 
        "vector": "string" 
        } 
    ]
    "AugT1": [
        {
        "word": "string", 
        "vector": "string"
        }
    ],
    "AugT2": [
        {
        "word": "string",
        "vector": "string"
        }
    ],
    "AugA1": [
        {
        "word": "string", 
        "vector": "string" 
        } 
    ], 
    "AugA2": [ 
        { 
        "word": "string", 
        "vector": "string" 
        } 
    ]
}
            </code></pre></p>
        </div>
        </div>
        <hr class="my-4">
        <p class="lead">API output formats</p>
        <div class="row">
        <div class="col">
            <a>Bias evaluation response for "ALL" methods</a>
            <p><pre><code>
{
   "EmbeddingSpace":"string",
   "EvaluationMethods":"string",
   "ECT-Value1": number,
   "ECT-P-Value1": number,
   "ECT-Value2": number,
   "ECT-P-Value2": number,
   "BAT-Value": number,
   "WEAT-effect-size": number,
   "WEAT-p-value": number,
   "K-Means-value": number,
   "T1":"string",
   "T2":"string",
   "A1":"string",
   "A2":"string"
}
            </code></pre></p>
        </div>
        <div class="col">
            <p>Response format for a debiasing-request </p>
            <p><pre><code>
{ 
    "EmbeddingSpace":"string",
    "Method":"string",
    "BiasedVecs:": { 
        "word1": "string",
        "word2": "string",
        "word3": "string",
        "word4": "string"
    }
    "DebiasedVecs": {
        "word1": "string",
        "word2": "string",
        "word3": "string",
        "word4": "string"
    }
}
            </code></pre></p>
        </div>
        <div class="col">
            <p>Response format for a debiasing-request with PCA enabled:</p>
            <p><pre><code>
{ 
    "EmbeddingSpace":"string",
    "Method":"string",
    "BiasedVecs:": { 
        "word1": "string",
        "word2": "string",
        "word3": "string",
        "word4": "string"
    }
    "DebiasedVecs": {
        "word1": "string",
        "word2": "string",
        "word3": "string",
        "word4": "string"
    }
    "BiasedVecsPCA:": { 
        "word1": "string",
        "word2": "string",
        "word3": "string",
        "word4": "string"
    }
    "DebiasedVecsPCA": {
        "word1": "string",
        "word2": "string",
        "word3": "string",
        "word4": "string"
    }
}
            </code></pre></p>
        </div>
        </div>
        <hr class="my-4">
        <p class="lead">Upload Embedding Space</p>
        <div class="row">
        <div class="col">
            <p>Accepted format for embedding space uploads:</p>
            <p><pre><code>
word1 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word2 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word3 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word4 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word5 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word6 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word7 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word8 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
word9 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 ...
...
            </code></pre></p>
        </div>
        </div>
    </div>

    <div class="container-fluid">
        <div class="jumbotron">
            <h1 class="display-4">RESTful API</h1>
            <hr class="my-4">
            <p class="lead">Usage</p> 
            <p>For evaluating bias and debiasing it is not necessarily to use this web application as a front-end. In some cases it might be useful to connect 
                directly to the back-end of this application. Therefore, the REST-ful API can be used. The API is accessible via the link:
                <a href="wifo5-29.informatik.uni-mannheim.de:8000/REST/test">wifo5-29.informatik.uni-mannheim.de:8000/REST/</a>.
                The complete documentation of the API can be found by following the link below.</p>
            <p class="lead"><a href="/swagger/index.html">Swagger Documentation</a></p>
        </div>
    </div>

    <div class="container-fluid">
        <div class="jumbotron">
            <h1 class="display-4">Pre-Trained Word Embeddings</h1>
            <hr class="my-4">
            <p class="lead">Used word vector spaces</p>
            <ul class="list-unstyled text-small">
                <li><a> fastText embedding space pre-trained on wikipedia 2017 with dimension 300, containing 1 Million words: <a href="https://fasttext.cc/docs/en/english-vectors.html">fastText</a></a></li>
                <li><a> Skip-gram embedding space pre-trained on wikipedia 2013 with dimension 250, containing 1 Million words: <a href="https://vsmlib.readthedocs.io/en/latest/tutorial/getting_vectors.html#">vsmlib</a></a></li>
                <li><a> CBOW embedding space pre-trained on wikipedia 2017 with dimension 300, containing 1 Million words: <a href="https://fasttext.cc/docs/en/crawl-vectors.html">fastText CBOW</a></a></li>
                <li><a> GloVe embedding space pre-trained on wikipedia 2014 with dimension 300, containing 1 Million words: <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a></a></li>
                <li><a> Post-specialized word vector embedding space by Ponti et al. 2016 for retrieving augmentations: <a href="https://arxiv.org/pdf/1809.04163.pdf">Post-Spezialized Space</a></a></li>
            </ul> 
            
            
        </div>
    </div>

    <footer class="container py-5">
        <div class="row">
            <div class="col-12 col-md">
            <img src="img/logo.png" width="128" height="64">
            <img src="img/logo-nkf.png" width="32" height="32"> 
            <small class="d-block mb-3 ml-3 text-muted">&copy; 2019-2020</small>
        </div>
        <div class="col-6 col-md">
            <h5>About</h5>
            <ul class="list-unstyled text-small">
                <li><a class="text-muted" href="https://arxiv.org/abs/1607.04606">fastText</a></li>
                <li><a class="text-muted" href="https://arxiv.org/pdf/1301.3781.pdf">SkipGram & CBOW</a></li>
                <li><a class="text-muted" href="https://nlp.stanford.edu/pubs/glove.pdf">GloVe</a></li>
                <li><a class="text-muted" href="/about.html">Vector sources</a></li>
            </ul>
        </div>
        <div class="col-6 col-md">
            <h5>Related Work</h5>
            <ul class="list-unstyled text-small">
                <li><a class="text-muted" href="https://arxiv.org/abs/1909.06092">General Framework</a></li>
                <li><a class="text-muted" href="https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf">Bolukbasi et al. 2016</a></li>
                <li><a class="text-muted" href="https://arxiv.org/abs/1608.07187">Caliskan et al. 2017</a></li>
                <li><a class="text-muted" href="http://proceedings.mlr.press/v89/dev19a/dev19a.pdf">Dev & Philips 2019</a></li>
                
            </ul>
        </div>
        <div class="col-6 col-md">
            <h5>Impressum</h5>
            <ul class="list-unstyled text-small">
                <li><a class="text-muted">Bachelor Thesis by Niklas Friedrich</a></li>
                <li><a class="text-muted">Supervised by Anne Lauscher and Prof. Dr. Goran Glava≈°</a></li>
                <li><a class="text-muted" href="https://www.uni-mannheim.de/dws/">Data and Web Science Group</a></li>
                <li><a class="text-muted" href="https://www.uni-mannheim.de">University of Mannheim</a></li>
            </ul>
        </div>
        </div>
    </footer>

</body>
